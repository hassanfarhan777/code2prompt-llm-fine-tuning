{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e6a89a",
   "metadata": {},
   "source": [
    "## Multiyear Code-to-Prompt Dataset Builder for 3Blue1Brown Repository\n",
    "#\n",
    " This notebook traverses a multi-year code repository (such as 3Blue1Brown's \"videos-master\"), extracts all Python files, and uses an LLM to generate a natural language prompt for each code file. It then saves the results as year-wise and combined datasets, and summarizes key statistics.\n",
    "\n",
    " **Main Features:**\n",
    " - Processes all years (2015‚Äì2025) or a selection\n",
    " - Handles nested subdirectories and skips hidden/cache folders\n",
    " - Generates robust (prompt, code, metadata) records for each file\n",
    " - Outputs CSV datasets and summary statistics for downstream ML/LLM research\n",
    "\n",
    "\n",
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df21cd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 17:29:38.236593: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-29 17:29:38.775976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-29 17:29:38.932421: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-29 17:29:38.992503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 17:29:39.364588: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-29 17:29:42.468316: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import tensorflow as tf\n",
    "import openai\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59459a2",
   "metadata": {},
   "source": [
    "### 2. API Key Setup and Utility Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1450fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h/Hassan.Mo/scratch/llm_env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading API Key from file\n",
    "folder_path = \"/scratch/h/Hassan.Mo/LLM/\"\n",
    "os.chdir(folder_path)\n",
    "API_KEY = open(\"open_ai_API.txt\", \"r\").read().strip()\n",
    "openai.api_key = API_KEY\n",
    "from utils import llm_tools, tools_local\n",
    "lt = llm_tools(api_key=openai.api_key)\n",
    "tl = tools_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739062d5",
   "metadata": {},
   "source": [
    "### 3. Comprehensive Directory Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c47571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_directory_comprehensive(\n",
    "    base_path=\"/scratch/h/Hassan.Mo/LLM/Scrapping/videos-master\",\n",
    "    years_to_process=None,  # None means all years\n",
    "    max_files_per_dir=None,  # None means all files\n",
    "    output_dir=\"/scratch/h/Hassan.Mo/LLM/datasets/\",\n",
    "    create_separate_datasets=True,  # Create both individual year datasets and combined\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Comprehensive processor for all 3B1B video directories\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base path to videos-master directory\n",
    "        years_to_process: List of years to process (e.g., [2015, 2016]) or None for all\n",
    "        max_files_per_dir: Maximum files to process per directory (None for all)\n",
    "        output_dir: Directory to save output CSV files\n",
    "        create_separate_datasets: Whether to create individual year datasets\n",
    "        verbose: Whether to print detailed processing info\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Determine years to process\n",
    "    if years_to_process is None:\n",
    "        years_to_process = list(range(2015, 2026))  # 2015-2025\n",
    "    \n",
    "    # Storage for all data\n",
    "    all_datasets = {}  # year -> [(prompt, code, metadata), ...]\n",
    "    combined_dataset = []\n",
    "    \n",
    "    print(f\"üöÄ Starting comprehensive processing of 3B1B repository\")\n",
    "    print(f\"üìÅ Base path: {base_path}\")\n",
    "    print(f\"üìÖ Years to process: {years_to_process}\")\n",
    "    print(f\"üíæ Output directory: {output_dir}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for year in years_to_process:\n",
    "        year_dir = os.path.join(base_path, f\"_{year}\")\n",
    "        \n",
    "        if not os.path.exists(year_dir):\n",
    "            if verbose:\n",
    "                print(f\"‚ö†Ô∏è  Year {year} directory not found, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüìÇ Processing Year: {year}\")\n",
    "        print(f\"   Path: {year_dir}\")\n",
    "        \n",
    "        year_data = []\n",
    "        year_stats = {\"directories\": 0, \"files\": 0, \"success\": 0, \"errors\": 0}\n",
    "        \n",
    "        # Process all subdirectories in the year folder\n",
    "        for root, dirs, files in os.walk(year_dir):\n",
    "            # Skip hidden directories and __pycache__\n",
    "            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']\n",
    "            \n",
    "            if not files:  # Skip directories with no files\n",
    "                continue\n",
    "                \n",
    "            # Filter for Python files\n",
    "            python_files = [f for f in files if f.endswith('.py')]\n",
    "            if not python_files:\n",
    "                continue\n",
    "                \n",
    "            rel_path = os.path.relpath(root, year_dir)\n",
    "            year_stats[\"directories\"] += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   üìÅ Processing subdirectory: {rel_path}\")\n",
    "                print(f\"      Found {len(python_files)} Python files\")\n",
    "            \n",
    "            # Process Python files in this directory\n",
    "            files_processed = 0\n",
    "            for py_file in sorted(python_files):\n",
    "                if max_files_per_dir and files_processed >= max_files_per_dir:\n",
    "                    if verbose:\n",
    "                        print(f\"      ‚èπÔ∏è  Reached max files limit ({max_files_per_dir})\")\n",
    "                    break\n",
    "                \n",
    "                file_path = os.path.join(root, py_file)\n",
    "                year_stats[\"files\"] += 1\n",
    "                \n",
    "                try:\n",
    "                    # Read the Python file\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        file_content = f.read()\n",
    "                    \n",
    "                    # Skip empty files or files with only imports\n",
    "                    if len(file_content.strip()) < 50:\n",
    "                        continue\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"      üîÑ Processing: {py_file} ({len(file_content)} chars)\")\n",
    "                    \n",
    "                    # Generate prompt using GPT\n",
    "                    response = lt.prompt_generator(file_content)\n",
    "                    response_text = response.choices[0].message.content\n",
    "                    \n",
    "                    # Extract the actual prompt from GPT response\n",
    "                    extracted_prompts = tl.extract_quoted_text([response_text], verbose=False)\n",
    "                    \n",
    "                    if extracted_prompts and extracted_prompts[0].strip():\n",
    "                        prompt = extracted_prompts[0].strip()\n",
    "                    else:\n",
    "                        # Fallback: use the full response if extraction fails\n",
    "                        prompt = response_text.strip()\n",
    "                    \n",
    "                    # Create metadata\n",
    "                    metadata = {\n",
    "                        \"year\": year,\n",
    "                        \"subdirectory\": rel_path,\n",
    "                        \"filename\": py_file,\n",
    "                        \"file_size\": len(file_content),\n",
    "                        \"relative_path\": os.path.join(rel_path, py_file)\n",
    "                    }\n",
    "                    \n",
    "                    # Store the data\n",
    "                    data_entry = (prompt, file_content, metadata)\n",
    "                    year_data.append(data_entry)\n",
    "                    combined_dataset.append(data_entry)\n",
    "                    \n",
    "                    year_stats[\"success\"] += 1\n",
    "                    files_processed += 1\n",
    "                    \n",
    "                    # Small delay to avoid overwhelming the API\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    year_stats[\"errors\"] += 1\n",
    "                    if verbose:\n",
    "                        print(f\"      ‚ùå Error processing {py_file}: {str(e)[:100]}...\")\n",
    "        \n",
    "        # Store year data\n",
    "        all_datasets[year] = year_data\n",
    "        \n",
    "        # Print year summary\n",
    "        print(f\"   ‚úÖ Year {year} Summary:\")\n",
    "        print(f\"      Directories: {year_stats['directories']}\")\n",
    "        print(f\"      Files found: {year_stats['files']}\")\n",
    "        print(f\"      Successfully processed: {year_stats['success']}\")\n",
    "        print(f\"      Errors: {year_stats['errors']}\")\n",
    "        \n",
    "        # Save individual year dataset if requested\n",
    "        if create_separate_datasets and year_data:\n",
    "            save_dataset(year_data, f\"3b1b_{year}_dataset.csv\", output_dir, verbose)\n",
    "    \n",
    "    # Save combined dataset\n",
    "    if combined_dataset:\n",
    "        save_dataset(combined_dataset, \"3b1b_complete_dataset.csv\", output_dir, verbose)\n",
    "        \n",
    "        # Create summary statistics\n",
    "        create_dataset_summary(all_datasets, output_dir, verbose)\n",
    "    \n",
    "    print(f\"\\nüéâ Processing complete!\")\n",
    "    print(f\"üìä Total entries processed: {len(combined_dataset)}\")\n",
    "    print(f\"üíæ Datasets saved to: {output_dir}\")\n",
    "    \n",
    "    return all_datasets, combined_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f66a39",
   "metadata": {},
   "source": [
    "### 4. Utility Functions for Saving & Summarizing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_dataset(data, filename, output_dir, verbose=True):\n",
    "    \"\"\"Save dataset to CSV with proper formatting\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    prompts = [entry[0] for entry in data]\n",
    "    codes = [entry[1] for entry in data]\n",
    "    metadata_list = [entry[2] for entry in data]\n",
    "    \n",
    "    # Create comprehensive DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'prompt': prompts,\n",
    "        'code': codes,\n",
    "        'year': [m['year'] for m in metadata_list],\n",
    "        'subdirectory': [m['subdirectory'] for m in metadata_list],\n",
    "        'filename': [m['filename'] for m in metadata_list],\n",
    "        'file_size': [m['file_size'] for m in metadata_list],\n",
    "        'relative_path': [m['relative_path'] for m in metadata_list]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"üíæ Saved {len(df)} entries to: {filepath}\")\n",
    "\n",
    "def create_dataset_summary(all_datasets, output_dir, verbose=True):\n",
    "    \"\"\"Create a summary of the dataset\"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for year, data in all_datasets.items():\n",
    "        if not data:\n",
    "            continue\n",
    "            \n",
    "        # Calculate statistics\n",
    "        file_sizes = [entry[2]['file_size'] for entry in data]\n",
    "        prompt_lengths = [len(entry[0]) for entry in data]\n",
    "        \n",
    "        # Get unique subdirectories\n",
    "        subdirs = list(set(entry[2]['subdirectory'] for entry in data))\n",
    "        \n",
    "        summary_data.append({\n",
    "            'year': year,\n",
    "            'total_files': len(data),\n",
    "            'unique_subdirectories': len(subdirs),\n",
    "            'subdirectories': ', '.join(sorted(subdirs)),\n",
    "            'avg_file_size': np.mean(file_sizes),\n",
    "            'avg_prompt_length': np.mean(prompt_lengths),\n",
    "            'total_code_chars': sum(file_sizes),\n",
    "            'total_prompt_chars': sum(prompt_lengths)\n",
    "        })\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = os.path.join(output_dir, \"dataset_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"üìä Dataset summary saved to: {summary_path}\")\n",
    "        display(HTML(summary_df.to_html(index=False)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd011e1",
   "metadata": {},
   "source": [
    "### 5. Example usage configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc235dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_all_years():\n",
    "    \"\"\"Process all years (2015-2025)\"\"\"\n",
    "    return process_directory_comprehensive(\n",
    "        years_to_process=None,  # All years\n",
    "        max_files_per_dir=None,  # All files\n",
    "        create_separate_datasets=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "def process_specific_years(years=[2015, 2016, 2017]):\n",
    "    \"\"\"Process specific years only\"\"\"\n",
    "    return process_directory_comprehensive(\n",
    "        years_to_process=years,\n",
    "        max_files_per_dir=None,\n",
    "        create_separate_datasets=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "def process_sample_dataset():\n",
    "    \"\"\"Create a sample dataset (max 5 files per directory)\"\"\"\n",
    "    return process_directory_comprehensive(\n",
    "        years_to_process=[2015, 2016],  # Just a few years for testing\n",
    "        max_files_per_dir=5,  # Limit files per directory\n",
    "        create_separate_datasets=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "# Quick execution functions\n",
    "def run_full_processing():\n",
    "    \"\"\"Run the complete processing of all years\"\"\"\n",
    "    print(\"üöÄ Starting FULL processing of all 3B1B years...\")\n",
    "    all_datasets, combined_dataset = process_all_years()\n",
    "    return all_datasets, combined_dataset\n",
    "\n",
    "def run_sample_processing():\n",
    "    \"\"\"Run a sample processing for testing\"\"\"\n",
    "    print(\"üß™ Starting SAMPLE processing for testing...\")\n",
    "    all_datasets, combined_dataset = process_sample_dataset()\n",
    "    return all_datasets, combined_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8fc9e3",
   "metadata": {},
   "source": [
    "### 6. Run Processing (Choose Full or Sample)\n",
    "#\n",
    " Uncomment the desired line below to run either full or sample processing.\n",
    " This will trigger the pipeline and produce datasets/statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting FULL processing of all 3B1B years...\n",
      "üöÄ Starting comprehensive processing of 3B1B repository\n",
      "üìÅ Base path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master\n",
      "üìÖ Years to process: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
      "üíæ Output directory: /scratch/h/Hassan.Mo/LLM/datasets/\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÇ Processing Year: 2015\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2015\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 14 Python files\n",
      "      üîÑ Processing: complex_multiplication_article.py (8148 chars)\n",
      "      üîÑ Processing: counting_in_binary.py (14636 chars)\n",
      "      üîÑ Processing: eulers_characteristic_formula.py (39442 chars)\n",
      "      üîÑ Processing: generate_logo.py (2376 chars)\n",
      "      üîÑ Processing: inventing_math.py (73398 chars)\n",
      "      üîÑ Processing: inventing_math_images.py (4498 chars)\n",
      "      üîÑ Processing: matrix_as_transform_2d.py (18433 chars)\n",
      "      üîÑ Processing: moser_intro.py (8483 chars)\n",
      "      üîÑ Processing: moser_main.py (61004 chars)\n",
      "      üîÑ Processing: music_and_measure.py (53516 chars)\n",
      "      üîÑ Processing: playground_counting_in_binary.py (6451 chars)\n",
      "      üîÑ Processing: pythagorean_proof.py (17728 chars)\n",
      "      üîÑ Processing: tau_poem.py (17846 chars)\n",
      "      üîÑ Processing: three_dimensions.py (3567 chars)\n",
      "   üìÅ Processing subdirectory: ka_playgrounds\n",
      "      Found 6 Python files\n",
      "      üîÑ Processing: circuits.py (6422 chars)\n",
      "      üîÑ Processing: fluid_flow.py (14055 chars)\n",
      "      üîÑ Processing: jacobian_animations.py (4009 chars)\n",
      "      üîÑ Processing: parametric_curves.py (1654 chars)\n",
      "      üîÑ Processing: transform_article.py (10385 chars)\n",
      "   ‚úÖ Year 2015 Summary:\n",
      "      Directories: 2\n",
      "      Files found: 20\n",
      "      Successfully processed: 19\n",
      "      Errors: 0\n",
      "üíæ Saved 19 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2015_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2016\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2016\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: fractal_charm.py (3099 chars)\n",
      "      üîÑ Processing: hanoi.py (109426 chars)\n",
      "      üîÑ Processing: patreon.py (20999 chars)\n",
      "      üîÑ Processing: wcat.py (66194 chars)\n",
      "      üîÑ Processing: zeta.py (109591 chars)\n",
      "   üìÅ Processing subdirectory: triangle_of_power\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: end.py (10307 chars)\n",
      "      üîÑ Processing: intro.py (14767 chars)\n",
      "      üîÑ Processing: triangle.py (25884 chars)\n",
      "   üìÅ Processing subdirectory: eola\n",
      "      Found 16 Python files\n",
      "      üîÑ Processing: chapter0.py (31316 chars)\n",
      "      üîÑ Processing: chapter1.py (40050 chars)\n",
      "      üîÑ Processing: chapter10.py (77521 chars)\n",
      "      üîÑ Processing: chapter11.py (85076 chars)\n",
      "      üîÑ Processing: chapter2.py (38193 chars)\n",
      "      üîÑ Processing: chapter3.py (57167 chars)\n",
      "      üîÑ Processing: chapter4.py (36678 chars)\n",
      "      üîÑ Processing: chapter5.py (35648 chars)\n",
      "      üîÑ Processing: chapter6.py (65396 chars)\n",
      "      üîÑ Processing: chapter7.py (76691 chars)\n",
      "      üîÑ Processing: chapter8.py (57144 chars)\n",
      "      üîÑ Processing: chapter8p2.py (32343 chars)\n",
      "      üîÑ Processing: chapter9.py (61621 chars)\n",
      "      üîÑ Processing: footnote.py (13153 chars)\n",
      "      üîÑ Processing: footnote2.py (20023 chars)\n",
      "      üîÑ Processing: thumbnails.py (4029 chars)\n",
      "   üìÅ Processing subdirectory: hilbert\n",
      "      Found 4 Python files\n",
      "      üîÑ Processing: fractal_porn.py (9389 chars)\n",
      "      üîÑ Processing: section1.py (31367 chars)\n",
      "      üîÑ Processing: section2.py (32587 chars)\n",
      "      üîÑ Processing: section3.py (8559 chars)\n",
      "   üìÅ Processing subdirectory: brachistochrone\n",
      "      Found 8 Python files\n",
      "      üîÑ Processing: curves.py (21750 chars)\n",
      "      üîÑ Processing: cycloid.py (17776 chars)\n",
      "      üîÑ Processing: drawing_images.py (11377 chars)\n",
      "      üîÑ Processing: graveyard.py (10893 chars)\n",
      "      üîÑ Processing: light.py (30643 chars)\n",
      "      üîÑ Processing: misc.py (15277 chars)\n",
      "      üîÑ Processing: multilayered.py (13867 chars)\n",
      "      üîÑ Processing: wordplay.py (16624 chars)\n",
      "   ‚úÖ Year 2016 Summary:\n",
      "      Directories: 5\n",
      "      Files found: 36\n",
      "      Successfully processed: 36\n",
      "      Errors: 0\n",
      "üíæ Saved 36 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2016_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2017\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2017\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 16 Python files\n",
      "      üîÑ Processing: 256.py (27080 chars)\n",
      "      üîÑ Processing: bell.py (77474 chars)\n",
      "      üîÑ Processing: borsuk.py (84077 chars)\n",
      "      üîÑ Processing: cba.py (12663 chars)\n",
      "      üîÑ Processing: crypto.py (164906 chars)\n",
      "      üîÑ Processing: efvgt.py (108031 chars)\n",
      "      üîÑ Processing: fractal_dimension.py (89124 chars)\n",
      "      üîÑ Processing: gradient.py (12267 chars)\n",
      "      üîÑ Processing: highD.py (116301 chars)\n",
      "      üîÑ Processing: leibniz.py (153517 chars)\n",
      "      üîÑ Processing: mug.py (66942 chars)\n",
      "      üîÑ Processing: putnam.py (52417 chars)\n",
      "      üîÑ Processing: qa_round_two.py (5669 chars)\n",
      "      üîÑ Processing: tattoo.py (27363 chars)\n",
      "      üîÑ Processing: triples.py (99381 chars)\n",
      "      üîÑ Processing: waves.py (135480 chars)\n",
      "   üìÅ Processing subdirectory: dominos\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: domino_play.py (23855 chars)\n",
      "   üìÅ Processing subdirectory: nn\n",
      "      Found 6 Python files\n",
      "      üîÑ Processing: mnist_loader.py (3596 chars)\n",
      "      üîÑ Processing: network.py (12688 chars)\n",
      "      üîÑ Processing: part1.py (142324 chars)\n",
      "      üîÑ Processing: part2.py (119410 chars)\n",
      "      üîÑ Processing: part3.py (146599 chars)\n",
      "      üîÑ Processing: playground.py (4840 chars)\n",
      "   üìÅ Processing subdirectory: eoc\n",
      "      Found 12 Python files\n",
      "      üîÑ Processing: chapter1.py (87436 chars)\n",
      "      üîÑ Processing: chapter10.py (114300 chars)\n",
      "      üîÑ Processing: chapter2.py (82051 chars)\n",
      "      üîÑ Processing: chapter3.py (88910 chars)\n",
      "      üîÑ Processing: chapter4.py (74265 chars)\n",
      "      üîÑ Processing: chapter5.py (63814 chars)\n",
      "      üîÑ Processing: chapter6.py (83716 chars)\n",
      "      üîÑ Processing: chapter7.py (93823 chars)\n",
      "      üîÑ Processing: chapter8.py (85165 chars)\n",
      "      üîÑ Processing: chapter9.py (65706 chars)\n",
      "      üîÑ Processing: footnote.py (27768 chars)\n",
      "      üîÑ Processing: old_chapter1.py (83983 chars)\n",
      "   ‚úÖ Year 2017 Summary:\n",
      "      Directories: 4\n",
      "      Files found: 35\n",
      "      Successfully processed: 35\n",
      "      Errors: 0\n",
      "üíæ Saved 35 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2017_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2018\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2018\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 22 Python files\n",
      "      üîÑ Processing: WindingNumber.py (102360 chars)\n",
      "      üîÑ Processing: WindingNumber_G.py (102790 chars)\n",
      "      üîÑ Processing: alt_calc.py (120093 chars)\n",
      "      üîÑ Processing: borsuk_addition.py (36622 chars)\n",
      "      üîÑ Processing: cramer.py (78301 chars)\n",
      "      üîÑ Processing: dandelin.py (53688 chars)\n",
      "      üîÑ Processing: determinant_puzzle.py (9156 chars)\n",
      "      üîÑ Processing: div_curl.py (139404 chars)\n",
      "      üîÑ Processing: fc1.py (7914 chars)\n",
      "      üîÑ Processing: for_flammy.py (9846 chars)\n",
      "      üîÑ Processing: fourier.py (141487 chars)\n",
      "      üîÑ Processing: gauss.py (7650 chars)\n",
      "      üîÑ Processing: holomorphic.py (5801 chars)\n",
      "      üîÑ Processing: lost_lecture.py (132163 chars)\n",
      "      üîÑ Processing: mvcr.py (21017 chars)\n",
      "      üîÑ Processing: pi_day.py (35079 chars)\n",
      "      üîÑ Processing: quat3d.py (46659 chars)\n",
      "      üîÑ Processing: quaternions.py (198184 chars)\n",
      "      üîÑ Processing: sphere_area.py (108858 chars)\n",
      "      üîÑ Processing: turbulence.py (51741 chars)\n",
      "      üîÑ Processing: uncertainty.py (152953 chars)\n",
      "      üîÑ Processing: wallis.py (175619 chars)\n",
      "   üìÅ Processing subdirectory: eop\n",
      "      Found 9 Python files\n",
      "      üîÑ Processing: bayes.py (71715 chars)\n",
      "      üîÑ Processing: bayes_footnote.py (47372 chars)\n",
      "      üîÑ Processing: birthday.py (726 chars)\n",
      "      üîÑ Processing: chapter0.py (2249 chars)\n",
      "      üîÑ Processing: combinations.py (116717 chars)\n",
      "      üîÑ Processing: independence.py (109843 chars)\n",
      "      üîÑ Processing: pascal.py (9926 chars)\n",
      "      üîÑ Processing: reusable_imports.py (524 chars)\n",
      "      üîÑ Processing: what_does_probability_mean.py (802 chars)\n",
      "   üìÅ Processing subdirectory: eop/chapter1\n",
      "      Found 20 Python files\n",
      "      üîÑ Processing: all_sequences.py (2185 chars)\n",
      "      üîÑ Processing: area_model_bayes.py (7511 chars)\n",
      "      üîÑ Processing: area_model_erf.py (3170 chars)\n",
      "      üîÑ Processing: area_model_expectation.py (2904 chars)\n",
      "      üîÑ Processing: brick_row_scene.py (34389 chars)\n",
      "      üîÑ Processing: entire_brick_wall.py (4824 chars)\n",
      "      üîÑ Processing: intro.py (1441 chars)\n",
      "      üîÑ Processing: just_randy_flipping_coin.py (943 chars)\n",
      "      üîÑ Processing: million_flips.py (3942 chars)\n",
      "      üîÑ Processing: morph_brick_row_into_histogram.py (8892 chars)\n",
      "      üîÑ Processing: prob_dist_visuals.py (9281 chars)\n",
      "      üîÑ Processing: quiz_result.py (8692 chars)\n",
      "      üîÑ Processing: show_proportion.py (3491 chars)\n",
      "      üîÑ Processing: show_uncertainty_darts.py (1139 chars)\n",
      "      üîÑ Processing: show_uncertainty_dice.py (1494 chars)\n",
      "      üîÑ Processing: show_uncertainty_disease.py (2645 chars)\n",
      "      üîÑ Processing: stacking_coins.py (1005 chars)\n",
      "      üîÑ Processing: think_about_coin.py (755 chars)\n",
      "      üîÑ Processing: various_intro_visuals.py (3352 chars)\n",
      "      üîÑ Processing: what_does_probability_mean.py (1378 chars)\n",
      "   üìÅ Processing subdirectory: eop/chapter2\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: permutation_grid.py (2813 chars)\n",
      "   üìÅ Processing subdirectory: eop/reusables\n",
      "      Found 11 Python files\n",
      "      üîÑ Processing: binary_option.py (407 chars)\n",
      "      üîÑ Processing: brick_row.py (6386 chars)\n",
      "      üîÑ Processing: coin_flip_tree.py (2365 chars)\n",
      "      üîÑ Processing: coin_flipping_pi_creature.py (3471 chars)\n",
      "      üîÑ Processing: coin_stacks.py (2937 chars)\n",
      "      üîÑ Processing: dice.py (1846 chars)\n",
      "      üîÑ Processing: eop_constants.py (432 chars)\n",
      "      üîÑ Processing: eop_helpers.py (840 chars)\n",
      "      üîÑ Processing: histograms.py (10205 chars)\n",
      "      üîÑ Processing: sick_pi_creature.py (427 chars)\n",
      "      üîÑ Processing: upright_coins.py (4450 chars)\n",
      "   üìÅ Processing subdirectory: eop/chapter0\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: intro.py (2249 chars)\n",
      "   üìÅ Processing subdirectory: basel\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: basel.py (135412 chars)\n",
      "      üîÑ Processing: basel2.py (148457 chars)\n",
      "   ‚úÖ Year 2018 Summary:\n",
      "      Directories: 7\n",
      "      Files found: 66\n",
      "      Successfully processed: 66\n",
      "      Errors: 0\n",
      "üíæ Saved 66 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2018_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2019\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2019\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 10 Python files\n",
      "      üîÑ Processing: QA_2to21.py (7182 chars)\n",
      "      üîÑ Processing: aliquot.py (1824 chars)\n",
      "      üîÑ Processing: bimo_image.py (5938 chars)\n",
      "      üîÑ Processing: bimo_images.py (5938 chars)\n",
      "      üîÑ Processing: hyperdarts.py (79987 chars)\n",
      "      üîÑ Processing: minute_physics_gr_equations.py (5133 chars)\n",
      "      üîÑ Processing: moduli.py (28895 chars)\n",
      "      üîÑ Processing: spirals.py (141334 chars)\n",
      "      üîÑ Processing: valentines.py (3935 chars)\n",
      "      üîÑ Processing: windmill.py (120804 chars)\n",
      "   üìÅ Processing subdirectory: bayes\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: footnote.py (33932 chars)\n",
      "      üîÑ Processing: part1.py (146001 chars)\n",
      "   üìÅ Processing subdirectory: clacks\n",
      "      Found 4 Python files\n",
      "      üîÑ Processing: all_s2_scenes.py (2678 chars)\n",
      "      üîÑ Processing: name_bump.py (2422 chars)\n",
      "      üîÑ Processing: question.py (47443 chars)\n",
      "      üîÑ Processing: solution1.py (97270 chars)\n",
      "   üìÅ Processing subdirectory: clacks/solution2\n",
      "      Found 6 Python files\n",
      "      üîÑ Processing: block_collision_scenes.py (2038 chars)\n",
      "      üîÑ Processing: mirror_scenes.py (32605 chars)\n",
      "      üîÑ Processing: pi_creature_scenes.py (3723 chars)\n",
      "      üîÑ Processing: position_phase_space.py (71364 chars)\n",
      "      üîÑ Processing: simple_scenes.py (25021 chars)\n",
      "      üîÑ Processing: wordy_scenes.py (10165 chars)\n",
      "   üìÅ Processing subdirectory: diffyq\n",
      "      Found 7 Python files\n",
      "      üîÑ Processing: all_part1_scenes.py (2605 chars)\n",
      "      üîÑ Processing: all_part2_scenes.py (1213 chars)\n",
      "      üîÑ Processing: all_part3_scenes.py (1808 chars)\n",
      "      üîÑ Processing: all_part4_scenes.py (1812 chars)\n",
      "      üîÑ Processing: all_part5_scenes.py (97 chars)\n",
      "      üîÑ Processing: fourier_montage_scenes.py (738 chars)\n",
      "      üîÑ Processing: solve_pendulum_ode_sample_code.py (812 chars)\n",
      "   üìÅ Processing subdirectory: diffyq/part1\n",
      "      Found 6 Python files\n",
      "      üîÑ Processing: pendulum.py (55166 chars)\n",
      "      üîÑ Processing: phase_space.py (61956 chars)\n",
      "      üîÑ Processing: pi_scenes.py (14598 chars)\n",
      "      üîÑ Processing: shared_constructs.py (2593 chars)\n",
      "      üîÑ Processing: staging.py (86408 chars)\n",
      "      üîÑ Processing: wordy_scenes.py (23870 chars)\n",
      "   üìÅ Processing subdirectory: diffyq/part5\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: staging.py (44723 chars)\n",
      "   üìÅ Processing subdirectory: diffyq/part2\n",
      "      Found 6 Python files\n",
      "      üîÑ Processing: fourier_series.py (27599 chars)\n",
      "      üîÑ Processing: heat_equation.py (83557 chars)\n",
      "      üîÑ Processing: pi_scenes.py (3999 chars)\n",
      "      üîÑ Processing: shared_constructs.py (773 chars)\n",
      "      üîÑ Processing: staging.py (21234 chars)\n",
      "      üîÑ Processing: wordy_scenes.py (23088 chars)\n",
      "   üìÅ Processing subdirectory: diffyq/part3\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: discrete_case.py (8064 chars)\n",
      "      üîÑ Processing: pi_creature_scenes.py (4907 chars)\n",
      "      üîÑ Processing: staging.py (34949 chars)\n",
      "      üîÑ Processing: temperature_graphs.py (77821 chars)\n",
      "      üîÑ Processing: wordy_scenes.py (24966 chars)\n",
      "   üìÅ Processing subdirectory: diffyq/part4\n",
      "      Found 7 Python files\n",
      "      üîÑ Processing: complex_functions.py (19538 chars)\n",
      "      üîÑ Processing: fourier_series_scenes.py (55402 chars)\n",
      "      üîÑ Processing: long_fourier_scenes.py (6525 chars)\n",
      "      üîÑ Processing: pi_creature_scenes.py (6726 chars)\n",
      "      üîÑ Processing: staging.py (71686 chars)\n",
      "      üîÑ Processing: temperature_scenes.py (10402 chars)\n",
      "      üîÑ Processing: three_d_graphs.py (13793 chars)\n",
      "   ‚úÖ Year 2019 Summary:\n",
      "      Directories: 10\n",
      "      Files found: 54\n",
      "      Successfully processed: 54\n",
      "      Errors: 0\n",
      "üíæ Saved 54 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2019_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2020\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2020\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 13 Python files\n",
      "      üîÑ Processing: antipode.py (105 chars)\n",
      "      üîÑ Processing: block_for_quanta.py (2108 chars)\n",
      "      üîÑ Processing: chess.py (155342 chars)\n",
      "      üîÑ Processing: covid.py (61812 chars)\n",
      "      üîÑ Processing: ctracing.py (21622 chars)\n",
      "      üîÑ Processing: hamming.py (199654 chars)\n",
      "      üîÑ Processing: ldm.py (36336 chars)\n",
      "      üîÑ Processing: med_test.py (219493 chars)\n",
      "      üîÑ Processing: monster.py (142888 chars)\n",
      "      üîÑ Processing: patreon_tier_images.py (2380 chars)\n",
      "      üîÑ Processing: sir.py (97121 chars)\n",
      "      üîÑ Processing: surface_play.py (1611 chars)\n",
      "      üîÑ Processing: telestration_contribution.py (7680 chars)\n",
      "   üìÅ Processing subdirectory: 18S191\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: convolutions.py (5948 chars)\n",
      "      üîÑ Processing: dft.py (11425 chars)\n",
      "      üîÑ Processing: diffusion.py (7766 chars)\n",
      "      üîÑ Processing: dynamic_prog.py (8171 chars)\n",
      "      üîÑ Processing: seam_carving.py (770 chars)\n",
      "   üìÅ Processing subdirectory: beta\n",
      "      Found 4 Python files\n",
      "      üîÑ Processing: beta1.py (113836 chars)\n",
      "      üîÑ Processing: beta2.py (68626 chars)\n",
      "      üîÑ Processing: beta3.py (64171 chars)\n",
      "      üîÑ Processing: helpers.py (16523 chars)\n",
      "   ‚úÖ Year 2020 Summary:\n",
      "      Directories: 3\n",
      "      Files found: 22\n",
      "      Successfully processed: 22\n",
      "      Errors: 0\n",
      "üíæ Saved 22 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2020_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2021\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2021\n",
      "   üìÅ Processing subdirectory: .\n",
      "      Found 9 Python files\n",
      "      üîÑ Processing: bertrands_paradox.py (34205 chars)\n",
      "      üîÑ Processing: holomorphic_dynamics.py (110678 chars)\n",
      "      üîÑ Processing: matrix_exp.py (213867 chars)\n",
      "      üîÑ Processing: newton_fractal.py (156891 chars)\n",
      "      üîÑ Processing: quick_eigen.py (93508 chars)\n",
      "      üîÑ Processing: shadows.py (210456 chars)\n",
      "      üîÑ Processing: siggraph.py (7684 chars)\n",
      "      üîÑ Processing: some1.py (37521 chars)\n",
      "      üîÑ Processing: some1_winners.py (25605 chars)\n",
      "   ‚úÖ Year 2021 Summary:\n",
      "      Directories: 1\n",
      "      Files found: 9\n",
      "      Successfully processed: 9\n",
      "      Errors: 0\n",
      "üíæ Saved 9 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2021_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2022\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2022\n",
      "   üìÅ Processing subdirectory: puzzles\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: subsets.py (183638 chars)\n",
      "   üìÅ Processing subdirectory: galois\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: art_supplements.py (5958 chars)\n",
      "      üîÑ Processing: groups.py (1763 chars)\n",
      "   üìÅ Processing subdirectory: zeta\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: part1.py (2453 chars)\n",
      "   üìÅ Processing subdirectory: infinity\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: roar_to_picture.py (14302 chars)\n",
      "   üìÅ Processing subdirectory: quintic\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: cubic.py (8839 chars)\n",
      "      üîÑ Processing: polynomial_baisics.py (51444 chars)\n",
      "      üîÑ Processing: roots_and_coefs.py (29405 chars)\n",
      "   üìÅ Processing subdirectory: visual_proofs\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: lies.py (80269 chars)\n",
      "   üìÅ Processing subdirectory: piano\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: fourier_animations.py (30469 chars)\n",
      "      üîÑ Processing: midi_animations.py (5276 chars)\n",
      "      üîÑ Processing: wav_to_midi.py (15274 chars)\n",
      "   üìÅ Processing subdirectory: borwein\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: main.py (64314 chars)\n",
      "      üîÑ Processing: supplements.py (19892 chars)\n",
      "   üìÅ Processing subdirectory: some2\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: announcement.py (8885 chars)\n",
      "      üîÑ Processing: winners.py (46353 chars)\n",
      "   üìÅ Processing subdirectory: convolutions\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: discrete.py (97198 chars)\n",
      "      üîÑ Processing: supplements.py (16130 chars)\n",
      "   üìÅ Processing subdirectory: wordle\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: footnote.py (27620 chars)\n",
      "      üîÑ Processing: scenes.py (140879 chars)\n",
      "      üîÑ Processing: simulations.py (32536 chars)\n",
      "   ‚úÖ Year 2022 Summary:\n",
      "      Directories: 11\n",
      "      Files found: 21\n",
      "      Successfully processed: 21\n",
      "      Errors: 0\n",
      "üíæ Saved 21 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2022_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2023\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2023\n",
      "   üìÅ Processing subdirectory: gauss_int\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: herschel.py (52389 chars)\n",
      "      üîÑ Processing: integral.py (45391 chars)\n",
      "      üîÑ Processing: supplements.py (44232 chars)\n",
      "   üìÅ Processing subdirectory: clt_proof\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: main.py (50984 chars)\n",
      "   üìÅ Processing subdirectory: convolutions2\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: continuous.py (76120 chars)\n",
      "      üîÑ Processing: diagonal_slices.py (32360 chars)\n",
      "      üîÑ Processing: dice.py (51789 chars)\n",
      "      üîÑ Processing: gauss_example_supplements.py (41144 chars)\n",
      "      üîÑ Processing: supplements.py (30151 chars)\n",
      "   üìÅ Processing subdirectory: clt\n",
      "      Found 4 Python files\n",
      "      üîÑ Processing: dice_sims.py (10116 chars)\n",
      "      üîÑ Processing: galton_board.py (21551 chars)\n",
      "      üîÑ Processing: main.py (118514 chars)\n",
      "      üîÑ Processing: wordy_scenes.py (39023 chars)\n",
      "   üìÅ Processing subdirectory: standup_maths\n",
      "      Found 2 Python files\n",
      "      üîÑ Processing: basketball.py (6783 chars)\n",
      "      üîÑ Processing: pool.py (10317 chars)\n",
      "   üìÅ Processing subdirectory: optics_puzzles\n",
      "      Found 11 Python files\n",
      "      üîÑ Processing: adding_waves.py (36191 chars)\n",
      "      üîÑ Processing: annotations.py (41971 chars)\n",
      "      üîÑ Processing: bending_waves.py (26579 chars)\n",
      "      üîÑ Processing: cylinder.py (43083 chars)\n",
      "      üîÑ Processing: driven_harmonic_oscillator.py (37693 chars)\n",
      "      üîÑ Processing: e_field.py (71384 chars)\n",
      "      üîÑ Processing: ior_annotations.py (50288 chars)\n",
      "      üîÑ Processing: objects.py (35327 chars)\n",
      "      üîÑ Processing: slowing_waves.py (28546 chars)\n",
      "      üîÑ Processing: slowing_waves_insert_embed.py (28202 chars)\n",
      "      üîÑ Processing: wave_machine.py (4532 chars)\n",
      "   üìÅ Processing subdirectory: moser_reboot\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: main.py (41690 chars)\n",
      "   üìÅ Processing subdirectory: SoME3\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: main.py (16107 chars)\n",
      "   üìÅ Processing subdirectory: numberphile\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: prime_race.py (7080 chars)\n",
      "   ‚úÖ Year 2023 Summary:\n",
      "      Directories: 9\n",
      "      Files found: 29\n",
      "      Successfully processed: 29\n",
      "      Errors: 0\n",
      "üíæ Saved 29 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2023_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2024\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2024\n",
      "   üìÅ Processing subdirectory: puzzles\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: added_dimension.py (108527 chars)\n",
      "      üîÑ Processing: max_rand.py (19797 chars)\n",
      "      üîÑ Processing: supplements.py (30168 chars)\n",
      "   üìÅ Processing subdirectory: linalg\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: eigenlecture.py (11739 chars)\n",
      "   üìÅ Processing subdirectory: manim_demo\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: lorenz.py (3110 chars)\n",
      "   üìÅ Processing subdirectory: antp\n",
      "      Found 1 Python files\n",
      "      üîÑ Processing: main.py (34412 chars)\n",
      "   üìÅ Processing subdirectory: inscribed_rect\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: helpers.py (5359 chars)\n",
      "      üîÑ Processing: loops.py (109334 chars)\n",
      "      üîÑ Processing: supplements.py (24435 chars)\n",
      "   üìÅ Processing subdirectory: holograms\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: diffraction.py (150180 chars)\n",
      "      üîÑ Processing: model.py (2760 chars)\n",
      "      üîÑ Processing: supplements.py (59312 chars)\n",
      "   üìÅ Processing subdirectory: transformers\n",
      "      Found 12 Python files\n",
      "      üîÑ Processing: almost_orthogonal.py (1503 chars)\n",
      "      üîÑ Processing: attention.py (145649 chars)\n",
      "      üîÑ Processing: auto_regression.py (19992 chars)\n",
      "      üîÑ Processing: chm.py (73014 chars)\n",
      "      üîÑ Processing: embedding.py (103240 chars)\n",
      "      üîÑ Processing: generation.py (31681 chars)\n",
      "      üîÑ Processing: helpers.py (26013 chars)\n",
      "      üîÑ Processing: ml_basics.py (82902 chars)\n",
      "      üîÑ Processing: mlp.py (93461 chars)\n",
      "      üîÑ Processing: network_flow.py (52207 chars)\n",
      "      üîÑ Processing: old_auto_regression.py (19992 chars)\n",
      "      üîÑ Processing: supplements.py (72232 chars)\n",
      "   ‚úÖ Year 2024 Summary:\n",
      "      Directories: 7\n",
      "      Files found: 24\n",
      "      Successfully processed: 24\n",
      "      Errors: 0\n",
      "üíæ Saved 24 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2024_dataset.csv\n",
      "\n",
      "üìÇ Processing Year: 2025\n",
      "   Path: /scratch/h/Hassan.Mo/LLM/Scrapping/videos-master/_2025\n",
      "   üìÅ Processing subdirectory: grover\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: clarification.py (50346 chars)\n",
      "      üîÑ Processing: polarization.py (14057 chars)\n",
      "      üîÑ Processing: qc_supplements.py (47357 chars)\n",
      "      üîÑ Processing: runtime.py (43248 chars)\n",
      "      üîÑ Processing: state_vectors.py (112294 chars)\n",
      "   üìÅ Processing subdirectory: cosmic_distance\n",
      "      Found 5 Python files\n",
      "      üîÑ Processing: paralax.py (31734 chars)\n",
      "      üîÑ Processing: part2.py (48602 chars)\n",
      "      üîÑ Processing: planets.py (109111 chars)\n",
      "      üîÑ Processing: supplements.py (44442 chars)\n",
      "      üîÑ Processing: supplements2.py (46159 chars)\n",
      "   üìÅ Processing subdirectory: colliding_blocks_v2\n",
      "      Found 3 Python files\n",
      "      üîÑ Processing: blocks.py (73388 chars)\n",
      "      üîÑ Processing: grover.py (4715 chars)\n",
      "      üîÑ Processing: supplements.py (43488 chars)\n",
      "   ‚úÖ Year 2025 Summary:\n",
      "      Directories: 3\n",
      "      Files found: 13\n",
      "      Successfully processed: 13\n",
      "      Errors: 0\n",
      "üíæ Saved 13 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_2025_dataset.csv\n",
      "üíæ Saved 328 entries to: /scratch/h/Hassan.Mo/LLM/datasets/3b1b_complete_dataset.csv\n",
      "üìä Dataset summary saved to: /scratch/h/Hassan.Mo/LLM/datasets/dataset_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>total_files</th>\n",
       "      <th>unique_subdirectories</th>\n",
       "      <th>subdirectories</th>\n",
       "      <th>avg_file_size</th>\n",
       "      <th>avg_prompt_length</th>\n",
       "      <th>total_code_chars</th>\n",
       "      <th>total_prompt_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>., ka_playgrounds</td>\n",
       "      <td>19265.842105</td>\n",
       "      <td>676.105263</td>\n",
       "      <td>366051</td>\n",
       "      <td>12846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>., brachistochrone, eola, hilbert, triangle_of_power</td>\n",
       "      <td>36456.250000</td>\n",
       "      <td>666.277778</td>\n",
       "      <td>1312425</td>\n",
       "      <td>23986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>., dominos, eoc, nn</td>\n",
       "      <td>75341.171429</td>\n",
       "      <td>655.085714</td>\n",
       "      <td>2636941</td>\n",
       "      <td>22928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>., basel, eop, eop/chapter0, eop/chapter1, eop/chapter2, eop/reusables</td>\n",
       "      <td>38233.166667</td>\n",
       "      <td>603.090909</td>\n",
       "      <td>2523389</td>\n",
       "      <td>39804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>., bayes, clacks, clacks/solution2, diffyq, diffyq/part1, diffyq/part2, diffyq/part3, diffyq/part4, diffyq/part5</td>\n",
       "      <td>30908.518519</td>\n",
       "      <td>627.888889</td>\n",
       "      <td>1669060</td>\n",
       "      <td>33906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>., 18S191, beta</td>\n",
       "      <td>56608.545455</td>\n",
       "      <td>618.772727</td>\n",
       "      <td>1245388</td>\n",
       "      <td>13613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>98935.000000</td>\n",
       "      <td>630.777778</td>\n",
       "      <td>890415</td>\n",
       "      <td>5677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>borwein, convolutions, galois, infinity, piano, puzzles, quintic, some2, visual_proofs, wordle, zeta</td>\n",
       "      <td>42042.714286</td>\n",
       "      <td>669.761905</td>\n",
       "      <td>882897</td>\n",
       "      <td>14065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>SoME3, clt, clt_proof, convolutions2, gauss_int, moser_reboot, numberphile, optics_puzzles, standup_maths</td>\n",
       "      <td>37915.068966</td>\n",
       "      <td>755.965517</td>\n",
       "      <td>1099537</td>\n",
       "      <td>21923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2024</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>antp, holograms, inscribed_rect, linalg, manim_demo, puzzles, transformers</td>\n",
       "      <td>53375.791667</td>\n",
       "      <td>784.083333</td>\n",
       "      <td>1281019</td>\n",
       "      <td>18818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>colliding_blocks_v2, cosmic_distance, grover</td>\n",
       "      <td>51457.000000</td>\n",
       "      <td>689.615385</td>\n",
       "      <td>668941</td>\n",
       "      <td>8965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Processing complete!\n",
      "üìä Total entries processed: 328\n",
      "üíæ Datasets saved to: /scratch/h/Hassan.Mo/LLM/datasets/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_datasets, combined_dataset = run_full_processing()\n",
    "# all_datasets, combined_dataset = run_sample_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cd711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_dataset) # Should be `list` of (prompt, code, metadata) tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a64e0",
   "metadata": {},
   "source": [
    "# ---\n",
    "### Next Steps & Notes\n",
    "#\n",
    " - Inspect the CSV files and summary table produced.\n",
    " - For large-scale ML or research use cases, consider inspecting random samples or adding more validation logic.\n",
    " - For more efficient large-scale processing (thousands of files), investigate batching or asynchrony.\n",
    "\n",
    " **This notebook is now fully documented with comments and markdown.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
